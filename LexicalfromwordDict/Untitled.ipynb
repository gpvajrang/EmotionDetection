{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "sns.set_style('darkgrid')\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punctuations = string.punctuation\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list = stopwords.words(\"english\")\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "def clean(text):\n",
    "    cleaned_text = text.lower()\n",
    "    cleaned_text=re.sub(\"[^a-zA-Z]\",\" \",cleaned_text)\n",
    "    cleaned_text=re.sub(r'\\b\\w{1,3}\\b', '',cleaned_text)\n",
    "\n",
    "    cleaned_text = \"\".join(c for c in cleaned_text if c not in punctuations)\n",
    "    words = cleaned_text.split()\n",
    "    words = [w for w in words if w not in stopword_list]\n",
    "     \n",
    "    words = [lem.lemmatize(word,\"v\") for word in words]\n",
    "    words = [lem.lemmatize(word,\"n\") for word in words]\n",
    "    words = [lem.lemmatize(word,\"r\") for word in words]\n",
    "    cleaned_text = \" \".join(words)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>At the point today where if someone says somet...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@CorningFootball  IT'S GAME DAY!!!!      T MIN...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This game has pissed me off more than any othe...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@spamvicious I've just found out it's Candice ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  At the point today where if someone says somet...  anger\n",
       "1  @CorningFootball  IT'S GAME DAY!!!!      T MIN...  anger\n",
       "2  This game has pissed me off more than any othe...  anger\n",
       "3  @spamvicious I've just found out it's Candice ...  anger\n",
       "4  @moocowward @mrsajhargreaves @Melly77 @GaryBar...  anger"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('tweetdata.csv')\n",
    "df.drop(columns =['id', 'Unnamed: 0', 'score'],axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    txt = str(text)\n",
    "    txt = re.sub(r\"http\\S+\", \"\", txt)\n",
    "    if len(txt) == 0:\n",
    "        return 'no text'\n",
    "    else:\n",
    "        txt = txt.split()\n",
    "        index = 0\n",
    "        for j in range(len(txt)):\n",
    "            if txt[j][0] == '@':\n",
    "                index = j\n",
    "        txt = np.delete(txt, index)\n",
    "        if len(txt) == 0:\n",
    "            return 'no text'\n",
    "        else:\n",
    "            words = txt[0]\n",
    "            for k in range(len(txt)-1):\n",
    "                words+= \" \" + txt[k+1]\n",
    "            txt = words\n",
    "            txt = re.sub(r'[^\\w]', ' ', txt)\n",
    "            if len(txt) == 0:\n",
    "                return 'no text'\n",
    "            else:\n",
    "                txt = ''.join(''.join(s)[:2] for _, s in itertools.groupby(txt))\n",
    "                txt = txt.replace(\"'\", \"\")\n",
    "                txt = nltk.tokenize.word_tokenize(txt)\n",
    "                #data.content[i] = [w for w in data.content[i] if not w in stopset]\n",
    "                for j in range(len(txt)):\n",
    "                    txt[j] = lem.lemmatize(txt[j], \"v\")\n",
    "                if len(txt) == 0:\n",
    "                    return 'no text'\n",
    "                else:\n",
    "                    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['clean_text'].map(lambda x: cleaning(x))\n",
    "        \n",
    "df = df.reset_index(drop=True)\n",
    "for i in range(len(df)):\n",
    "    words = df.clean_text[i][0]\n",
    "    for j in range(len(df.clean_text[i])-1):\n",
    "        words+= ' ' + df.clean_text[i][j+1]\n",
    "    df.clean_text[i] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = int(np.round(len(df)*0.75))\n",
    "train = df.iloc[:x,:].reset_index(drop = True)\n",
    "test = df.iloc[x:,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\gp\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: click in c:\\users\\gp\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\gp\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2020.6.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gp\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.47.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\gp\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (0.16.0)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier as NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.540785498489426\n"
     ]
    }
   ],
   "source": [
    "training_corpus = []\n",
    "\n",
    "for k in range(len(train)):\n",
    "    training_corpus.append((train.clean_text[k], train.label[k]))    \n",
    "test_corpus = []\n",
    "\n",
    "for l in range(len(test)):\n",
    "    test_corpus.append((test.clean_text[l], test.label[l]))\n",
    "\n",
    "model = NBC(training_corpus)\n",
    "\n",
    "print(model.accuracy(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00         0\n",
      "        fear       0.96      0.15      0.25      1039\n",
      "         joy       0.55      0.83      0.66       823\n",
      "     sadness       0.53      0.76      0.63       786\n",
      "\n",
      "    accuracy                           0.54      2648\n",
      "   macro avg       0.51      0.43      0.38      2648\n",
      "weighted avg       0.70      0.54      0.49      2648\n",
      "\n",
      "processing time: 4515.350930452347 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = []\n",
    "for m in range(len(test)):\n",
    "    predictions.append(model.classify(test.clean_text[m]))\n",
    "print(classification_report(test.label, predictions))\n",
    "    \n",
    "predictions_df = pd.DataFrame({'clean_text':test.clean_text, 'Emotion_predicted':predictions, 'Emotion_actual':test.label})\n",
    "predictions_df.to_csv('naive_emotion_recognizer.csv', index = False)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print (\"processing time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Emotion_predicted</th>\n",
       "      <th>Emotion_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go submit wardrobe makeover show fear fashion</td>\n",
       "      <td>joy</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social medium another father take child nightm...</td>\n",
       "      <td>joy</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shaun</td>\n",
       "      <td>joy</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time stress always year age make redundant start</td>\n",
       "      <td>joy</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>steal tell</td>\n",
       "      <td>joy</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>much home stun happy think sink</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>n o   t e x t</td>\n",
       "      <td>anger</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>pretty love background purple highlight dull c...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>artist announcement look good bluesfest blue m...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>pesto pasta top grill chicken dry tomato aspar...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2648 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text Emotion_predicted  \\\n",
       "0         go submit wardrobe makeover show fear fashion               joy   \n",
       "1     social medium another father take child nightm...               joy   \n",
       "2                                                 shaun               joy   \n",
       "3      time stress always year age make redundant start               joy   \n",
       "4                                            steal tell               joy   \n",
       "...                                                 ...               ...   \n",
       "2643                    much home stun happy think sink           sadness   \n",
       "2644                                      n o   t e x t             anger   \n",
       "2645  pretty love background purple highlight dull c...           sadness   \n",
       "2646  artist announcement look good bluesfest blue m...           sadness   \n",
       "2647  pesto pasta top grill chicken dry tomato aspar...           sadness   \n",
       "\n",
       "     Emotion_actual  \n",
       "0              fear  \n",
       "1              fear  \n",
       "2              fear  \n",
       "3              fear  \n",
       "4              fear  \n",
       "...             ...  \n",
       "2643        sadness  \n",
       "2644        sadness  \n",
       "2645        sadness  \n",
       "2646        sadness  \n",
       "2647        sadness  \n",
       "\n",
       "[2648 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
